---
description: Daily Trader Project Essential Rules
globs: 
alwaysApply: true
---

# Daily Trader - Project Intelligence

## Core Architecture Patterns

### Service Layer Design
- **Pattern**: Each AI provider gets its own service class (BedrockService, OpenAIService)
- **Interface**: All services return `AsyncIterable<string>` for streaming
- **Error Handling**: Provider-specific errors are caught and handled within each service
- **Configuration**: Services read from centralized `config.ts` with environment validation

### Streaming Implementation
- **AsyncIterable Pattern**: Use `async function*` generators for streaming responses
- **Real-time Output**: Use `process.stdout.write(chunk)` for immediate display, not `console.log()`
- **Chunk Processing**: Parse streaming responses incrementally, handle partial JSON gracefully
- **Performance Metrics**: Track timing, chunk count, and content length for comparisons

### Configuration Management
- **Environment Variables**: All API keys and configuration through `.env` file
- **Validation**: Required variables throw descriptive errors if missing
- **Defaults**: Provide sensible defaults for optional configuration (regions, model IDs)
- **Type Safety**: Strong TypeScript interfaces for all configuration structures

## AWS Bedrock Specifics

### Model Integration
- **Claude Message Format**: Use `anthropic_version: 'bedrock-2023-05-31'` with messages array
- **Streaming Response**: Parse `content_block_delta` events with `delta.text` content
- **Model IDs**: Use full AWS model identifiers (e.g., `anthropic.claude-3-5-sonnet-20241022-v2:0`)
- **Error Patterns**: AWS SDK errors need specific handling for access/permission issues

### Request Structure
```typescript
{
  anthropic_version: 'bedrock-2023-05-31',
  max_tokens: number,
  temperature: number,
  messages: [{ role: 'user', content: string }]
}
```

## OpenAI Integration

### Streaming Pattern
- **Modern SDK**: Use OpenAI v5+ with `stream: true` parameter
- **Response Parsing**: Extract `chunk.choices[0]?.delta?.content` from stream
- **Error Handling**: OpenAI errors are different from AWS - handle API key and rate limit issues
- **Model Selection**: Support both GPT-3.5 and GPT-4 with convenience methods

## Development Workflow

### Package Management
- **pnpm**: Preferred package manager for this project
- **Scripts**: Use `tsx` for development, `tsc` for building
- **Development**: `pnpm dev` for quick testing, `pnpm dev:watch` for file watching

### Environment Setup
- **Template**: Always provide `.env.example` with all required variables
- **Security**: `.env` files are gitignored, never commit API keys
- **Regional**: AWS Bedrock availability varies by region - default to us-east-1

### Memory Bank Maintenance
- **Documentation**: Keep memory-bank/ files updated with architectural decisions
- **Progress Tracking**: Update progress.md and activeContext.md after major changes
- **Todo Management**: Use todo.md for tracking enhancements and technical debt

## Error Handling Philosophy

### Graceful Degradation
- **Provider Isolation**: Failure in one service doesn't break others
- **User-Friendly Messages**: Clear, actionable error messages
- **Configuration Validation**: Fail fast with descriptive messages for missing config
- **API Failures**: Continue testing other providers even if one fails

### Common Issues
- **Model Access**: AWS Bedrock may require requesting access to specific models
- **Rate Limits**: Both providers have different rate limiting strategies
- **Regions**: Some AWS Bedrock models aren't available in all regions
- **Credentials**: Invalid credentials should produce clear guidance messages

## Performance Considerations

### Streaming Efficiency
- **Immediate Display**: Don't buffer full responses, stream as available
- **Metrics Collection**: Track performance without impacting streaming speed
- **Memory Usage**: Use streaming to avoid loading full responses into memory
- **Comparison Fairness**: Use similar prompts and parameters across providers

### Scalability Patterns
- **Connection Pooling**: Consider for high-throughput scenarios
- **Rate Limiting**: Implement when moving to production
- **Concurrent Requests**: Current implementation is sequential by design
- **Error Recovery**: Implement retry logic with exponential backoff

## Testing Strategy

### Integration Focus
- **Real APIs**: Test against actual AWS Bedrock and OpenAI endpoints
- **Configuration Testing**: Verify error handling with invalid credentials  
- **Performance Baselines**: Establish baseline metrics for regression testing
- **Model Availability**: Test that configured models are accessible

### User Experience Testing
- **Output Clarity**: Ensure streaming output is readable and informative
- **Error Messages**: Verify error messages provide actionable guidance
- **Performance Display**: Metrics should be meaningful and comparable
- **Documentation**: README should enable successful setup from scratch
description:
globs:
alwaysApply: false
---
